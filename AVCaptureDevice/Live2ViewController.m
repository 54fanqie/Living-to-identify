//
//  Live2ViewController.m
//  AVCaptureDevice
//
//  Created by ç•ªèŒ„ on 2018/1/10.
//  Copyright Â© 2018å¹´ ç•ªèŒ„. All rights reserved.
//

#import "Live2ViewController.h"
#import <AVFoundation/AVFoundation.h>
#import <AssetsLibrary/AssetsLibrary.h>
#import <Photos/Photos.h>
#import <CoreImage/CoreImage.h>
#import "UIImage+FixOrientation.h"
#import "iflyMSC/IFlyFaceSDK.h"
#import "IFlyFaceImage.h"

@interface Live2ViewController ()<AVCaptureMetadataOutputObjectsDelegate,AVCaptureVideoDataOutputSampleBufferDelegate>

//æ•è·è®¾å¤‡ï¼Œé€šå¸¸æ˜¯å‰ç½®æ‘„åƒå¤´ï¼Œåç½®æ‘„åƒå¤´ï¼Œéº¦å…‹é£ï¼ˆéŸ³é¢‘è¾“å…¥ï¼‰
@property (nonatomic,strong) AVCaptureDevice *device;
//AVCaptureDeviceInput ä»£è¡¨è¾“å…¥è®¾å¤‡ï¼Œä»–ä½¿ç”¨AVCaptureDevice æ¥åˆå§‹åŒ–
@property (nonatomic,strong) AVCaptureDeviceInput *input;
//è¾“å‡ºå›¾ç‰‡
@property (nonatomic,strong) AVCaptureStillImageOutput *imageOutput;
//sessionï¼šç”±ä»–æŠŠè¾“å…¥è¾“å‡ºç»“åˆåœ¨ä¸€èµ·ï¼Œå¹¶å¼€å§‹å¯åŠ¨æ•è·è®¾å¤‡ï¼ˆæ‘„åƒå¤´ï¼‰
@property (nonatomic,strong) AVCaptureSession *session;
//å›¾åƒé¢„è§ˆå±‚ï¼Œå®æ—¶æ˜¾ç¤ºæ•è·çš„å›¾åƒ
@property (nonatomic,strong) AVCaptureVideoPreviewLayer *previewLayer;
@property (nonatomic,strong) AVCaptureVideoDataOutput * videoDataOutput;
@property (nonatomic,strong) AVCaptureMetadataOutput * metadataOutput;

@property (nonatomic, retain ) IFlyFaceDetector           *faceDetector;

//åŠ¨ç”»è§†å›¾å±‚
@property (nonatomic,strong) UIImageView * imageView;
//æ‰€æœ‰åŠ¨ä½œæ•°ç»„è§†å›¾
@property (nonatomic,strong) NSMutableArray * allAnimationImages;
//æ•è·åŠ¨ä½œçš„è§†å›¾
@property (nonatomic,strong) NSMutableArray * captureImages;
//æ•è·åŠ¨ä½œç æ•°ç»„
@property (nonatomic,strong) NSMutableArray * liveCodeList;

//éšæœºåŠ¨ä½œç æ•°ç»„
@property (nonatomic,strong) NSMutableArray * randomCode;
//éšæœºåŠ¨ç”»è§†å›¾ç»„
@property (nonatomic,strong) NSMutableArray * randImages;
//åŠ¨ç”»ç»„æ•°é¡ºåºç 
@property (nonatomic,assign) int countNum;
//åŠ¨ä½œç 
@property (nonatomic,assign) int changeCode;

//å¿…é¡»æ£€æµ‹åˆ°äººè„¸æ‰èƒ½å¼€å§‹äººè„¸è¯†åˆ«æµç¨‹
@property (nonatomic,assign) BOOL haveFace;
//å¼€å§‹è·å–åˆ°äººè„¸å›¾ç‰‡
@property (nonatomic,assign)  BOOL starFaceing;
//å·²æ£€æµ‹åˆ°äººè„¸æ ‡è¯†
@property (nonatomic,copy) UIImage * faceImage;

@property (nonatomic,strong) UIButton * button;
//è¯·æ±‚è¯†åˆ«ç»“æœæ¬¡æ•°
@property (nonatomic,assign) int requestTimeOut;

@property(nonatomic,strong) UILabel * textlabel;
//æ˜¯å¦æœ‰ç›¸æœºæƒé™
@property (nonatomic,assign) BOOL videoStatus;

@property(nonatomic,strong) NSMutableArray * images;

@property (nonatomic,assign) int gaga;
@end

#define randomNum  3  //éšæœºå–ä¸‰ç»„åŠ¨ç”»
#define ScreenHeight [UIScreen mainScreen].bounds.size.height
#define ScreenWidth [UIScreen mainScreen].bounds.size.width
@implementation Live2ViewController

- (void)viewDidLoad {
    [super viewDidLoad];
    // Do any additional setup after loading the view.
    self.starFaceing = NO;
    //ä¸»åŠ¨è·å–ç›¸æœºã€ç›¸å†Œæƒé™
    [self getPermissions];
    //åˆå§‹åŒ–ç›¸æœº
    [self initAVCaptureDevice];
    [self cameraDistrict];
}


-(void)initAVCaptureDevice{
    //    AVCaptureDevicePositionBack  åç½®æ‘„åƒå¤´
    //    AVCaptureDevicePositionFront å‰ç½®æ‘„åƒå¤´
    self.device = [self cameraWithPosition:AVCaptureDevicePositionFront];
    self.input = [[AVCaptureDeviceInput alloc] initWithDevice:self.device error:nil];
    
    self.imageOutput = [[AVCaptureStillImageOutput alloc] init];
    self.session = [[AVCaptureSession alloc] init];
    //è®¾å®šå›¾åƒçš„å¤§å°
    if ([self.session canSetSessionPreset:AVCaptureSessionPresetMedium]) {
        NSLog(@"ğŸ‰AVCaptureSessionPresetMediumğŸ‰");
        self.session.sessionPreset = AVCaptureSessionPresetMedium;
    }
    
    
    //è¾“å…¥è¾“å‡ºè®¾å¤‡ç»“åˆ
    if ([self.session canAddInput:self.input]) {
        [self.session addInput:self.input];
    }
    if ([self.session canAddOutput:self.imageOutput]) {
        NSDictionary * outputSettings = [[NSDictionary alloc] initWithObjectsAndKeys:AVVideoCodecJPEG,AVVideoCodecKey,nil];
        [self.imageOutput setOutputSettings:outputSettings];
        [self.session addOutput:self.imageOutput];
    }
    if ([_session canAddOutput:self.metadataOutput]) {
        [_session addOutput:self.metadataOutput];
        //è®¾ç½®æ‰«ç æ ¼å¼
        self.metadataOutput.metadataObjectTypes = @[AVMetadataObjectTypeFace];
    }
    if ([_session canAddOutput:self.videoDataOutput]) {
        [_session addOutput:self.videoDataOutput];
    }
    
    //é¢„è§ˆå±‚çš„ç”Ÿæˆ
    self.previewLayer = [[AVCaptureVideoPreviewLayer alloc] initWithSession:self.session];
    self.previewLayer.frame = CGRectMake(0,0, ScreenWidth, ScreenHeight);
    self.previewLayer.videoGravity = AVLayerVideoGravityResizeAspectFill;
    [self.view.layer addSublayer:self.previewLayer];
    
    //è®¾å¤‡å–æ™¯å¼€å§‹
    [self.session startRunning];
    if ([_device lockForConfiguration:nil]) {
        //è‡ªåŠ¨é—ªå…‰ç¯ï¼Œ
        if ([_device isFlashModeSupported:AVCaptureFlashModeAuto]) {
            [_device setFlashMode:AVCaptureFlashModeOff];
        }
        if ([_device isExposureModeSupported:AVCaptureExposureModeContinuousAutoExposure]) {
            CGPoint exposurePoint = CGPointMake(0.5f, 0.5f); // æ›å…‰ç‚¹ä¸ºä¸­å¿ƒ
            [_device setExposurePointOfInterest:exposurePoint];
            [_device setExposureMode:AVCaptureExposureModeContinuousAutoExposure];
        }
        [_device unlockForConfiguration];
    }
    
    AVCaptureConnection *conntion = [self.videoDataOutput connectionWithMediaType:AVMediaTypeVideo];
    // æ‰“å¼€å½±é™¢çº§å…‰å­¦é˜²æŠ–
    conntion.preferredVideoStabilizationMode = AVCaptureVideoStabilizationModeCinematic;
    [conntion setVideoOrientation:AVCaptureVideoOrientationPortrait];
    
    self.faceDetector=[IFlyFaceDetector sharedInstance];
    [self.faceDetector setParameter:@"1" forKey:@"detect"];
    [self.faceDetector setParameter:@"1" forKey:@"align"];
}

-(AVCaptureDevice *)cameraWithPosition:(AVCaptureDevicePosition)position{
    NSArray *devices = [AVCaptureDevice devicesWithMediaType:AVMediaTypeVideo];
    for ( AVCaptureDevice *device in devices )
        if ( device.position == position ){
            return device;
        }
    return nil;
}
-(AVCaptureMetadataOutput *)metadataOutput{
    if (_metadataOutput == nil) {
        _metadataOutput = [[AVCaptureMetadataOutput alloc]init];
        dispatch_queue_t queue = dispatch_queue_create("myQueue2", NULL);
        [_metadataOutput setMetadataObjectsDelegate:self queue:queue];
        //è®¾ç½®æ‰«æåŒºåŸŸ
        _metadataOutput.rectOfInterest = self.view.bounds;
    }
    return _metadataOutput;
}
-(AVCaptureVideoDataOutput *)videoDataOutput{
    if (_videoDataOutput == nil) {
        _videoDataOutput = [[AVCaptureVideoDataOutput alloc] init];
        [_videoDataOutput setVideoSettings:[NSDictionary dictionaryWithObject:[NSNumber numberWithInt:kCVPixelFormatType_32BGRA] forKey:(id)kCVPixelBufferPixelFormatTypeKey]];
        dispatch_queue_t queue = dispatch_queue_create("myQueue", NULL);
        [_videoDataOutput setSampleBufferDelegate:self queue:queue];
    }
    return _videoDataOutput;
}

#pragma mark  è‡ªå®šä¹‰è§†å›¾
- (void)cameraDistrict
{
    CGFloat  width = 90;
    UIView * buttonView = [[UIView alloc]initWithFrame:CGRectMake(ScreenWidth/2 - (width +10)/2, ScreenHeight - width - 10 - 15, width, width )];
    buttonView.backgroundColor = [UIColor whiteColor];
    buttonView.layer.cornerRadius = width/2;
    [buttonView.layer masksToBounds];
    [self.view addSubview:buttonView];
    //è‡ªå·±å®šä¹‰ä¸€ä¸ªå’ŒåŸç”Ÿçš„ç›¸æœºä¸€æ ·çš„æŒ‰é’®ï¼Œå¼€å§‹æ£€æµ‹æŒ‰é’®
    _button= [UIButton buttonWithType:UIButtonTypeRoundedRect];
    _button.frame = CGRectMake(15/2, 15/2, width -15, width -15);
    _button.backgroundColor = [UIColor whiteColor];
    _button.layer.cornerRadius = (width -15)/2;
    _button.layer.borderWidth = 2;
    _button.layer.borderColor = [UIColor blackColor].CGColor;
    [_button.layer masksToBounds];
    [_button setTitle:@"å¼€å§‹æ£€æµ‹" forState:UIControlStateNormal];
    [_button addTarget:self action:@selector(strarDetection) forControlEvents:UIControlEventTouchUpInside];
    [buttonView addSubview:_button];
    
    self.textlabel = [[UILabel alloc]initWithFrame:CGRectMake((ScreenWidth-150)/2, ScreenHeight - width - 10 - 15 -30, 150, 30)];
    self.textlabel.textAlignment = NSTextAlignmentCenter;
    self.textlabel.layer.cornerRadius = 15;
    self.textlabel.text = @"è¯·æŒ‰æç¤ºåšåŠ¨ä½œ";
    self.textlabel.textColor = [UIColor whiteColor];
    [self.view addSubview:self.textlabel];
    
    
    UIImageView * faceBack = [[UIImageView alloc]initWithFrame:CGRectMake(0, 80, ScreenWidth, ScreenWidth * 1.135)];
    faceBack.image = [UIImage imageNamed:@"faceBounds.png"];
    [self.view addSubview:faceBack];
    
    self.imageView = [[UIImageView alloc]initWithFrame:CGRectMake(faceBack.center.x - 100, faceBack.center.y - 115 , 200, 230)];
    [self.view addSubview:self.imageView];
    
    //æµ‹è¯•æŒ‰é’®
    UIButton *save = [UIButton buttonWithType:UIButtonTypeRoundedRect];
    save.frame = CGRectMake(30, 30 , 60, 60);
    save.backgroundColor = [UIColor redColor];
    [save addTarget:self action:@selector(savePhoto) forControlEvents:UIControlEventTouchUpInside];
    [self.view addSubview:save];
    //åˆå§‹åŒ–
    [self initImageViewAnimation];
    self.gaga = 0;
}

#pragma mark - AVCaptureVideoDataOutputSampleBufferDelegate
//AVCaptureVideoDataOutputè·å–å®æ—¶å›¾åƒï¼Œè¿™ä¸ªä»£ç†æ–¹æ³•çš„å›è°ƒé¢‘ç‡å¾ˆå¿«ï¼Œå‡ ä¹ä¸æ‰‹æœºå±å¹•çš„åˆ·æ–°é¢‘ç‡ä¸€æ ·å¿«
-(void)captureOutput:(AVCaptureOutput *)captureOutput didOutputSampleBuffer:(CMSampleBufferRef)sampleBuffer fromConnection:(AVCaptureConnection *)connection{
    if(sampleBuffer == NULL){
        return ;
    }
    
    //    UIImage * largeImage = [self imageFromSampleBuffer:sampleBuffer];
    //
    //    NSDictionary *opts = [NSDictionary dictionaryWithObject:
    //                          CIDetectorAccuracyHigh forKey:CIDetectorAccuracy];
    //    // å°†å›¾åƒè½¬æ¢ä¸ºCIImage
    //    CIImage *faceImage = [CIImage imageWithCGImage:largeImage.CGImage];
    //    CIDetector *faceDetector=[CIDetector detectorOfType:CIDetectorTypeFace context:nil options:opts];
    //    // è¯†åˆ«å‡ºäººè„¸æ•°ç»„
    //    NSArray *features = [faceDetector featuresInImage:faceImage];
    //    CIFaceFeature *feature = nil;
    //
    //    CGRect rect;
    //
    //    for (CIFaceFeature *f in features)
    //
    //    {
    //
    //        CGRect aRect = f.bounds;
    //
    ////        NSLog(@"%f, %f, %f, %f", aRect.origin.x, aRect.origin.y, aRect.size.width, aRect.size.height);
    //        NSLog(@"è„¸é•¿%f, è„¸å®½%f", aRect.size.width, aRect.size.height);
    //        //çœ¼ç›å’Œå˜´çš„ä½ç½®
    //
    //        if(f.hasLeftEyePosition) NSLog(@"Left eyeï¼ˆå·¦çœ¼ï¼‰ %g %g\n", f.leftEyePosition.x, f.leftEyePosition.y);
    //
    //        if(f.hasRightEyePosition) NSLog(@"Right eyeï¼ˆå³çœ¼ï¼‰ %g %g\n", f.rightEyePosition.x, f.rightEyePosition.y);
    //
    //        if(f.hasMouthPosition)
    //
    //        {
    //
    ////            NSLog(@"Mouth %g %g %g %g\n", f.mouthPosition.x, f.mouthPosition.y,f.bounds.size.height,f.bounds.size.width);
    //
    //            feature = f;
    //
    //            rect = CGRectMake(f.mouthPosition.x - 100 , f.mouthPosition.yÂ  - 60, 200, 250);
    //
    //        }
    //
    //    }
    //
    
    //    IFlyFaceImage* faceImage=[self faceImageFromSampleBuffer:sampleBuffer];
    //     NSString* strResult=[self.faceDetector trackFrame:faceImage.data withWidth:faceImage.width height:faceImage.height direction:(int)faceImage.direction];
    //    UIImage * image = [UIImage imageWithData:faceImage.data];
    //    NSLog(@"%@",strResult);
    //     faceImage.data=nil;
    //    if(self.starFaceing){
    //        [NSThread sleepForTimeInterval:.4];
    //        if (self.starFaceing) {
    //            UIImage * largeImage = [self imageFromSampleBuffer:sampleBuffer];
    //            self.gaga++;
    //        NSString * title = [NSString stringWithFormat:@"%dâ€”â€”%d",self.gaga,self.changeCode];
    //        CGPoint point = CGPointMake(50, 300);
    //        NSDictionary * attributed = @{NSFontAttributeName: [UIFont boldSystemFontOfSize:50],NSForegroundColorAttributeName : [UIColor redColor]};
    //        largeImage = [UIImage jx_WaterStringWithImage:largeImage text:title textPoint:point attributedString:attributed];
    //        largeImage = [largeImage scaleToWidth:largeImage.size.width];
    //æ´»ä½“å›¾ç‰‡é‡‡é›†å¤„ç†å›¾ç‰‡
    //            [_captureImages addObject:largeImage];
    
    //å­˜å‚¨åŠ¨ä½œç 
    //            [self.liveCodeList addObject:self.randomCode[self.countNum]];
    //            NSLog(@"ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰%d------åŠ¨ä½œç %@",self.gaga,self.randomCode[self.countNum]);
    //        }
    //
    //    }else{
    //        NSLog(@"æš‚åœ  æš‚åœ");
    //    }
}
// Create a IFlyFaceImage from sample buffer data
- (IFlyFaceImage *) faceImageFromSampleBuffer:(CMSampleBufferRef) sampleBuffer
{
    //è·å–ç°åº¦å›¾åƒæ•°æ®
    CVPixelBufferRef pixelBuffer = (CVPixelBufferRef)CMSampleBufferGetImageBuffer(sampleBuffer);
    CVPixelBufferLockBaseAddress(pixelBuffer, 0);
    
    uint8_t *lumaBuffer  = (uint8_t *)CVPixelBufferGetBaseAddressOfPlane(pixelBuffer, 0);
    
    size_t bytesPerRow = CVPixelBufferGetBytesPerRowOfPlane(pixelBuffer,0);
    size_t width  = CVPixelBufferGetWidth(pixelBuffer);
    size_t height = CVPixelBufferGetHeight(pixelBuffer);
    
    CGColorSpaceRef grayColorSpace = CGColorSpaceCreateDeviceGray();
    
    CGContextRef context=CGBitmapContextCreate(lumaBuffer, width, height, 8, bytesPerRow, grayColorSpace,0);
    CGImageRef cgImage = CGBitmapContextCreateImage(context);
    
    CVPixelBufferUnlockBaseAddress(pixelBuffer, 0);
    
    IFlyFaceDirectionType faceOrientation=[self faceImageOrientation];
    
    IFlyFaceImage* faceImage=[[IFlyFaceImage alloc] init];
    if(!faceImage){
        return nil;
    }
    
    CGDataProviderRef provider = CGImageGetDataProvider(cgImage);
    
    faceImage.data= (__bridge_transfer NSData*)CGDataProviderCopyData(provider);
    faceImage.width=width;
    faceImage.height=height;
    faceImage.direction=faceOrientation;
    
    CGImageRelease(cgImage);
    CGContextRelease(context);
    CGColorSpaceRelease(grayColorSpace);
    
    return faceImage;
    
}
-(IFlyFaceDirectionType)faceImageOrientation
{
    IFlyFaceDirectionType faceOrientation=IFlyFaceDirectionTypeLeft;
    BOOL isFrontCamera=self.input.device.position==AVCaptureDevicePositionFront;
    switch (self.interfaceOrientation) {
        case UIDeviceOrientationPortrait:{//
            faceOrientation=IFlyFaceDirectionTypeLeft;
        }
            break;
        case UIDeviceOrientationPortraitUpsideDown:{
            faceOrientation=IFlyFaceDirectionTypeRight;
        }
            break;
        case UIDeviceOrientationLandscapeRight:{
            faceOrientation=isFrontCamera?IFlyFaceDirectionTypeUp:IFlyFaceDirectionTypeDown;
        }
            break;
        default:{//
            faceOrientation=isFrontCamera?IFlyFaceDirectionTypeDown:IFlyFaceDirectionTypeUp;
        }
            break;
    }
    
    return faceOrientation;
}

#pragma mark - AVCaptureMetadataOutputObjectsDelegate
-(void)captureOutput:(AVCaptureOutput *)captureOutput didOutputMetadataObjects:(NSArray *)metadataObjects fromConnection:(AVCaptureConnection *)connection{
    //æ•è·äººè„¸å“åº”
    //    [NSThread sleepForTimeInterval:1];
    if (metadataObjects.count>0) {
        AVMetadataMachineReadableCodeObject *metadataObject = [metadataObjects objectAtIndex :0];
        if (metadataObject.type == AVMetadataObjectTypeFace) {
            self.haveFace = YES;
            AVMetadataFaceObject *face = (AVMetadataFaceObject *)metadataObject;
            
            CGRect faceRectangle = [face bounds];
            CGRect faceRect = [_previewLayer rectForMetadataOutputRectOfInterest:faceRectangle];
            
            int w = (int)faceRect.size.width;
            int h = (int)faceRect.size.height;
            int x = (int)faceRect.origin.x;
            int y = (int)faceRect.origin.y;
            NSString * string = nil;
            NSLog(@" è„¸å¤§ä¸å¤§ --%d----%d",w,h);
            //            NSLog(@"xåç§» %f", ScreenWidth/2 - (w/2 + x));
            //            NSLog(@"yåç§» %f", ScreenHeight/2 - (h/2 + y));
            //åˆ¤æ–­ä½ç½®
            //            dispatch_async(dispatch_get_main_queue(), ^{
            //                if ( w < 200) {
            //                    NSLog(@"å¤ªè¿œäº†...");
            //                    self.textlabel.text = @"å¤ªè¿œäº†...";
            //                }else if (w > 300 ) {
            //                    NSLog(@"å¤ªè¿‘äº†...");
            //                    self.textlabel.text = @"å¤ªè¿‘äº†...";
            //                }else if((w/2 + x) + 30 < ScreenWidth/2 || (w/2 + x) - 30 > ScreenWidth/2){
            //                    NSLog(@"è°ƒæ•´å·¦å³é—´è·...");
            //                    self.textlabel.text = @"è°ƒæ•´å·¦å³é—´è·...";
            //                }else if( (h/2 + y) <  ScreenHeight - 20 || (h/2 + y) < ScreenHeight + 20){
            //                    NSLog(@"è°ƒæ•´ä¸Šä¸‹é—´è·...");
            //                    self.textlabel.text = @"è°ƒæ•´ä¸Šä¸‹é—´è·...";
            //                }else {
            //                    self.textlabel.text = @"";
            //                    NSLog(@"...");
            //                }
            //            });
            
            
            if ( w < 180) {
                NSLog(@"å¤ªè¿œäº†...");
                string = @"å¤ªè¿œäº†...";
            }else if (w > 250 ) {
                NSLog(@"å¤ªè¿‘äº†...");
                string = @"å¤ªè¿‘äº†...";
            }else if((w/2 + x) + 30 < ScreenWidth/2 || (w/2 + x) - 30 > ScreenWidth/2){
                NSLog(@"è°ƒæ•´å·¦å³é—´è·...");
                string= @"è°ƒæ•´å·¦å³é—´è·...";
            }else if( (h/2 + y) <  ScreenHeight/2 - 40 || (h/2 + y) > ScreenHeight/2 + 40){
                NSLog(@"è°ƒæ•´ä¸Šä¸‹é—´è·...");
                string = @"è°ƒæ•´ä¸Šä¸‹é—´è·...";
            }else{
                string = @"";
                NSLog(@"...");
            }
            dispatch_async(dispatch_get_main_queue(), ^{
                self.textlabel.text = string;
            });

        }
    }
    if (self.haveFace) {
        return;
    }
    
}
#pragma mark animation group
-(void)initImageViewAnimation{
    self.allAnimationImages = [NSMutableArray arrayWithArray:[self imageDatas]];
    self.randomCode = [NSMutableArray array];
    self.randImages = [NSMutableArray array];
    
    self.starFaceing = NO;
    self.haveFace = NO;
    //æ´»ä½“æ£€æµ‹å›¾ç‰‡ç»„
    _captureImages = [NSMutableArray array];
    //æ´»ä½“æ£€æµ‹åŠ¨ä½œç 
    _liveCodeList = [NSMutableArray array];
    //è®¾ç½®æ’­æ”¾å‘¨æœŸæ—¶é—´
    self.imageView.animationDuration = 4;
    //è®¾ç½®æ’­æ”¾æ¬¡æ•°
    self.imageView.animationRepeatCount = 1;
    //åˆå§‹åŒ–éšæœºåŠ¨ä½œæ•°ç»„
    [self randomAnimationImages];
    
}
//éšæœºåŠ¨ä½œç»„
-(void)randomAnimationImages{
    self.countNum = 0;
    if (self.randImages.count > 0) {
        [self.randImages removeAllObjects];
    }
    if (self.randomCode.count > 0) {
        [self.randomCode removeAllObjects];
    }
    
    NSMutableSet * randomSet = [[NSMutableSet alloc] init];
    while ([randomSet count] < randomNum) {
        int r = arc4random() % [self.allAnimationImages count];
        [randomSet addObject:[self.allAnimationImages objectAtIndex:r]];
    }
    NSArray *randomArray = [randomSet allObjects];
    //éšæœºåŠ¨ç”»ç»„
    [self.randImages addObjectsFromArray:randomArray];
    //éšæœºåŠ¨ä½œç 
    for (int i=0;i<randomNum;i++) {
        NSInteger inde =[self.allAnimationImages indexOfObject:randomArray[i]];
        if (inde != NSNotFound) {
            [self.randomCode addObject:@(inde + 1)];
        }else{
            NSLog(@"ä¸å­˜åœ¨");
        }
    }
    
}

#pragma mark å¼€å§‹åŠ¨ç”»->å¼€å§‹æˆªå›¾â€”>æäº¤æ´»ä½“å›¾ç‰‡->æäº¤äººè„¸å›¾ç‰‡->è¿›è¡Œç­¾å->æäº¤ç­¾å->è¿”å›
//è·å–äººè„¸è¯†åˆ«å¤´åƒ
-(void)strarDetection{
    if (!self.videoStatus) {
        NSLog(@"æ²¡æœ‰ç›¸æœºæƒé™");
        return ;
    }
    if (!self.haveFace) {
        NSLog(@"æ²¡æœ‰è¯†åˆ«åˆ°äººè„¸");
        return;
    }
    _button.userInteractionEnabled = NO;
    self.faceImage = nil;
    //è·å–äººè„¸è¯†åˆ«å›¾ç‰‡
    //    [self takingPictures];
    //è·å–æ´»ä½“è¯†åˆ«å›¾ç‰‡
    [self starLiveCollection];
}
//å…ˆåˆ¤æ–­æ˜¯å¦æœ‰äººè„¸ï¼Œåœ¨å¼€å¯åŠ¨ç”»ï¼Œå¼€å¯æˆªå›¾
-(void)starLiveCollection{
    //é‡ç½®åˆå§‹åŒ–å€¼
    self.countNum = 0;
    self.gaga = 0;
    if (_captureImages.count > 0) {
        [_captureImages removeAllObjects];
    }
    if (_liveCodeList.count > 0) {
        [_liveCodeList removeAllObjects];
    }
    
    [self starImageAnimationGroup];
    //å»¶è¿Ÿ1så¼€å§‹æˆªå›¾
    dispatch_time_t popTime = dispatch_time(DISPATCH_TIME_NOW, 0.8 * NSEC_PER_SEC);
    dispatch_after(popTime, dispatch_get_main_queue(), ^(void){
        self.starFaceing = YES;
        NSLog(@"ç¬¬1ç»„åŠ¨ä½œ");
    });
}
// åŠ¨ç”»å¼€å§‹
-(void)starImageAnimationGroup{
    
    //è®¾ç½®imageView.animationImagesåŠ¨ç”»ç»„
    self.imageView.animationImages = self.randImages[self.countNum];
    // æ’­æ”¾åŠ¨ç”»
    [self.imageView startAnimating];
    NSLog(@"å¼€å§‹åŠ¨ç”»");
    dispatch_after(dispatch_time(DISPATCH_TIME_NOW, (int64_t)(4 * NSEC_PER_SEC)), dispatch_get_main_queue(), ^{
        //æ¯ç»„å›¾ç‰‡é‡‡é›†å®Œæˆ
        self.starFaceing = NO;
        NSLog(@"dispatch_after enter timer,thread = %@", [NSThread currentThread]);
        [self.imageView stopAnimating];
        if (self.countNum < randomNum -1) {
            self.countNum ++;
            NSLog(@"åˆ‡æ¢ç»„åŠ¨ç”»");
            [self performSelector:@selector(changeImageGrounp) withObject:nil afterDelay:0.5];
        }else{
            [NSThread sleepForTimeInterval:1];
            //é‡ç½®åŠ¨ä½œ
            [self randomAnimationImages];
            [self uploadLiveImage];
        }
    });
    
}

-(void)changeImageGrounp{
    [self starImageAnimationGroup];
    dispatch_time_t popTime = dispatch_time(DISPATCH_TIME_NOW, 0.8 * NSEC_PER_SEC);
    dispatch_after(popTime, dispatch_get_main_queue(), ^(void){
        self.changeCode = self.countNum;
        self.starFaceing = YES;
        NSLog(@"ç¬¬%dç»„åŠ¨ä½œ",self.countNum + 1);
    });
    
}


//è¯·æ±‚æ´»ä½“æ£€æµ‹
-(void)uploadLiveImage{
    if(_captureImages.count==0){
        NSLog(@"æœªé‡‡é›†åˆ°å›¾ç‰‡ä¿¡æ¯");
        return;
    }
    //    UIImage * image = _captureImages[1];
    //    NSLog(@"æ´»ä½“æ£€æµ‹å›¾ç‰‡å°ºå¯¸ %.2f----%.2f",image.size.width * image.scale,image.size.height* image.scale);
    //    [self writeImages:_captureImages completion:^(id result) {
    //            NSLog(@"%@",result);
    //    }];
    //    largeImage = [UIImage imageWithCGImage:largeImage.CGImage scale:1 orientation:UIImageOrientationUp];
    int count = 0;
    NSMutableArray * images = [NSMutableArray array];
    for (UIImage * image in _captureImages) {
        count++;
        NSData * data = [image compressImageQuality:image toByte:10];
        UIImage * liveImg2  = [UIImage imageWithData:data];
        NSString * title = [NSString stringWithFormat:@"%dâ€”â€”%@",count,self.liveCodeList[count-1]];
        CGPoint point = CGPointMake(50, 300);
        NSDictionary * attributed = @{NSFontAttributeName: [UIFont boldSystemFontOfSize:50],NSForegroundColorAttributeName : [UIColor redColor]};
        liveImg2 = [UIImage jx_WaterStringWithImage:liveImg2 text:title textPoint:point attributedString:attributed];
        [images addObject:liveImg2];
        
    }
    _button.userInteractionEnabled = YES;
    //    [self writeImages:images completion:^(id result) {
    //        NSLog(@"%@",result);
    //    }];
    
}

//ä»AVCaptureDeviceè·å–å›¾ç‰‡
- (void)takingPictures
{
    static SystemSoundID soundID = 0;
    if (soundID == 0) {
        NSString *path = [[NSBundle mainBundle] pathForResource:@"photoShutter2" ofType:@"caf"];
        NSURL *filePath = [NSURL fileURLWithPath:path isDirectory:NO];
        AudioServicesCreateSystemSoundID((__bridge CFURLRef)filePath, &soundID);
    }
    AudioServicesPlaySystemSound(soundID);
    
    AVCaptureConnection *conntion = [self.imageOutput connectionWithMediaType:AVMediaTypeVideo];
    if (!conntion) {
        NSLog(@"æ‹ç…§å¤±è´¥!");
        return;
    }
    [self.imageOutput captureStillImageAsynchronouslyFromConnection:conntion completionHandler:^(CMSampleBufferRef imageDataSampleBuffer, NSError *error) {
        if (imageDataSampleBuffer == nil) {
            return ;
        }
        NSData *imageData = [AVCaptureStillImageOutput jpegStillImageNSDataRepresentation:imageDataSampleBuffer];
        UIImage * image = [UIImage imageWithData:imageData];
        image = [image fixOrientation];
        
        
        if ([self faceDetectWithImage:image]) {
            self.faceImage = image;
            [self requestFaceDetector];
        }else{
            dispatch_time_t popTime = dispatch_time(DISPATCH_TIME_NOW, 1 * NSEC_PER_SEC);
            dispatch_after(popTime, dispatch_get_main_queue(), ^(void){
                [self takingPictures];
            });
        }
    }];
}
#pragma mark - æœ¬åœ°è¯†åˆ«äººè„¸
- (BOOL)faceDetectWithImage:(UIImage *)image {
    
    // å›¾åƒè¯†åˆ«èƒ½åŠ›ï¼šå¯ä»¥åœ¨CIDetectorAccuracyHigh(è¾ƒå¼ºçš„å¤„ç†èƒ½åŠ›)ä¸CIDetectorAccuracyLow(è¾ƒå¼±çš„å¤„ç†èƒ½åŠ›)ä¸­é€‰æ‹©ï¼Œå› ä¸ºæƒ³è®©å‡†ç¡®åº¦é«˜ä¸€äº›åœ¨è¿™é‡Œé€‰æ‹©CIDetectorAccuracyHigh
    NSDictionary *opts = [NSDictionary dictionaryWithObject:
                          CIDetectorAccuracyHigh forKey:CIDetectorAccuracy];
    // å°†å›¾åƒè½¬æ¢ä¸ºCIImage
    CIImage *faceImage = [CIImage imageWithCGImage:image.CGImage];
    CIDetector *faceDetector=[CIDetector detectorOfType:CIDetectorTypeFace context:nil options:opts];
    // è¯†åˆ«å‡ºäººè„¸æ•°ç»„
    NSArray *features = [faceDetector featuresInImage:faceImage];
    
    if(features.count>0){
        NSLog(@"æ£€æµ‹åˆ°äººè„¸");
        return YES;
    }else{
        NSLog(@"æ£€æµ‹ä¸­......");
        return NO;
    }
}




// è¯·æ±‚äººè„¸è¯†åˆ«
-(void)requestFaceDetector{
    
    UIImage * image = [UIImage imageWithCGImage:self.faceImage.CGImage scale:1 orientation:UIImageOrientationLeftMirrored];
    NSData * data  = [image compressImageQuality:image toByte:100];
    NSLog(@"å¤§å°KB %d",((int)data.length)/1024);
    
    UIImageWriteToSavedPhotosAlbum(image, self, @selector(image:didFinishSavingWithError:contextInfo:), NULL);
}


-(void)savePhoto{
    [self takingPictures];
}


/**
 *  æ‰¹é‡å­˜å‚¨å›¾ç‰‡åˆ°ç›¸å†Œ
 */
- (void) writeImages:(NSMutableArray*)images completion:(void (^)(id result))completionHandler{
    
    ALAssetsLibrary *assetsLibrary = [[ALAssetsLibrary alloc] init];
    if ([images count] == 0) {
        if (completionHandler) {
            // Signal completion to the call-site. Use an appropriate result,
            // instead of @"finished" possibly pass an array of URLs and NSErrors
            // generated below  in "handle URL or error".
            completionHandler(@"finished");
        }
        return;
    }
    
    UIImage* image = [images firstObject];
    [images removeObjectAtIndex:0];
    
    
    [assetsLibrary writeImageToSavedPhotosAlbum:image.CGImage
                                    orientation:ALAssetOrientationUp
                                completionBlock:^(NSURL *assetURL, NSError *error)
     {
         // Caution: check the execution context - it may be any thread,
         // possibly use dispatch_async to dispatch to the main thread or
         // any other queue.
         
         // handle URL or error
         
         // next image:
         [self writeImages:images completion:completionHandler];
     }];
}

- (void)image:(UIImage *)image didFinishSavingWithError:(NSError *)error contextInfo:(void *)contextInfo
{
    
    NSLog(@"image = %@, error = %@, contextInfo = %@", image, error, contextInfo);
    
}



//ä¸»åŠ¨è·å–ç›¸æœºã€ç›¸å†Œæƒé™
-(void)getPermissions{
    [AVCaptureDevice requestAccessForMediaType:AVMediaTypeVideo completionHandler:^(BOOL granted) {
        NSLog(@"%@",granted ? @"ç›¸æœºå‡†è®¸":@"ç›¸æœºä¸å‡†è®¸");
        self.videoStatus = granted;
    }];
    [PHPhotoLibrary requestAuthorization:^(PHAuthorizationStatus status) {
        
    }];
}
//åˆå§‹åŒ–åŠ¨ç”»å›¾ç‰‡
-(NSArray*)imageDatas{
    UIImage * mouth_00 = [UIImage imageNamed:@"mouth_00.png"];
    UIImage * mouth_01 = [UIImage imageNamed:@"mouth_01.png"];
    
    UIImage * eye_00 = [UIImage imageNamed:@"eye_00.png"];
    UIImage * eye_01 = [UIImage imageNamed:@"eye_01.png"];
    
    UIImage * down_00 = [UIImage imageNamed:@"down_00.png"];
    UIImage * down_01 = [UIImage imageNamed:@"down_01.png"];
    
    UIImage * up_00 = [UIImage imageNamed:@"up_00.png"];
    UIImage * up_01 = [UIImage imageNamed:@"up_01.png"];
    
    UIImage * right_00 = [UIImage imageNamed:@"right_00.png"];
    UIImage * right_01 = [UIImage imageNamed:@"right_01.png"];
    
    UIImage * left_00 = [UIImage imageNamed:@"left_00.png"];
    UIImage * left_01 = [UIImage imageNamed:@"left_01.png"];
    
    
    //å¼ å˜´1
    NSMutableArray * imagesArray1 = [NSMutableArray array];
    [imagesArray1 addObject:mouth_00];
    [imagesArray1 addObject:mouth_01];
    [imagesArray1 addObject:mouth_00];
    [imagesArray1 addObject:mouth_01];
    [imagesArray1 addObject:mouth_00];
    //çœ¨çœ¼2
    NSMutableArray * imagesArray2 = [NSMutableArray array];
    [imagesArray2 addObject:eye_00];
    [imagesArray2 addObject:eye_01];
    [imagesArray2 addObject:eye_00];
    [imagesArray2 addObject:eye_01];
    [imagesArray2 addObject:eye_00];
    //ä½å¤´3
    NSMutableArray * imagesArray3 = [NSMutableArray array];
    [imagesArray3 addObject:down_00];
    [imagesArray3 addObject:down_01];
    [imagesArray3 addObject:down_00];
    [imagesArray3 addObject:down_01];
    [imagesArray3 addObject:down_00];
    //æŠ¬å¤´4
    NSMutableArray * imagesArray4 = [NSMutableArray array];
    [imagesArray4 addObject:up_00];
    [imagesArray4 addObject:up_01];
    [imagesArray4 addObject:up_00];
    [imagesArray4 addObject:up_01];
    [imagesArray4 addObject:up_00];
    //å³è½¬å¤´5
    NSMutableArray * imagesArray5 = [NSMutableArray array];
    [imagesArray5 addObject:right_00];
    [imagesArray5 addObject:right_01];
    [imagesArray5 addObject:right_00];
    [imagesArray5 addObject:right_01];
    [imagesArray5 addObject:right_00];
    //å·¦è½¬å¤´6
    NSMutableArray * imagesArray6 = [NSMutableArray array];
    [imagesArray6 addObject:left_00];
    [imagesArray6 addObject:left_01];
    [imagesArray6 addObject:left_00];
    [imagesArray6 addObject:left_01];
    [imagesArray6 addObject:left_00];
    
    
    NSMutableArray * initAnimationImages = [NSMutableArray array];
    [initAnimationImages addObject:imagesArray1];
    [initAnimationImages addObject:imagesArray2];
    [initAnimationImages addObject:imagesArray3];
    [initAnimationImages addObject:imagesArray4];
    [initAnimationImages addObject:imagesArray5];
    [initAnimationImages addObject:imagesArray6];
    
    return (NSArray*)initAnimationImages;
}


-(UIImage *)imageFromSampleBuffer:(CMSampleBufferRef)sampleBuffer{
    // ä¸ºåª’ä½“æ•°æ®è®¾ç½®ä¸€ä¸ªCMSampleBufferçš„Core Videoå›¾åƒç¼“å­˜å¯¹è±¡
    CVImageBufferRef imageBuffer = CMSampleBufferGetImageBuffer(sampleBuffer);
    // é”å®špixel bufferçš„åŸºåœ°å€
    CVPixelBufferLockBaseAddress(imageBuffer, 0);
    // å¾—åˆ°pixel bufferçš„åŸºåœ°å€
    void *baseAddress = CVPixelBufferGetBaseAddress(imageBuffer);
    // å¾—åˆ°pixel bufferçš„è¡Œå­—èŠ‚æ•°
    size_t bytesPerRow = CVPixelBufferGetBytesPerRow(imageBuffer);
    // å¾—åˆ°pixel bufferçš„å®½å’Œé«˜
    size_t width = CVPixelBufferGetWidth(imageBuffer);
    size_t height = CVPixelBufferGetHeight(imageBuffer);
    // åˆ›å»ºä¸€ä¸ªä¾èµ–äºè®¾å¤‡çš„RGBé¢œè‰²ç©ºé—´
    CGColorSpaceRef colorSpace = CGColorSpaceCreateDeviceRGB();
    // ç”¨æŠ½æ ·ç¼“å­˜çš„æ•°æ®åˆ›å»ºä¸€ä¸ªä½å›¾æ ¼å¼çš„å›¾å½¢ä¸Šä¸‹æ–‡ï¼ˆgraphics contextï¼‰å¯¹è±¡
    CGContextRef context = CGBitmapContextCreate(baseAddress, width, height, 8, bytesPerRow, colorSpace, kCGBitmapByteOrder32Little | kCGImageAlphaPremultipliedFirst);
    // æ ¹æ®è¿™ä¸ªä½å›¾contextä¸­çš„åƒç´ æ•°æ®åˆ›å»ºä¸€ä¸ªQuartz imageå¯¹è±¡
    CGImageRef quartzImage = CGBitmapContextCreateImage(context);
    // è§£é”pixel buffer
    CVPixelBufferUnlockBaseAddress(imageBuffer,0);
    // é‡Šæ”¾contextå’Œé¢œè‰²ç©ºé—´
    CGContextRelease(context); CGColorSpaceRelease(colorSpace);
    // ç”¨Quartz imageåˆ›å»ºä¸€ä¸ªUIImageå¯¹è±¡image
    UIImage *image = [UIImage imageWithCGImage:quartzImage];
    // é‡Šæ”¾Quartz imageå¯¹è±¡
    CGImageRelease(quartzImage);
    return (image);
}

-(void)dealloc{
    [self.session stopRunning];
}

- (void)didReceiveMemoryWarning {
    [super didReceiveMemoryWarning];
    // Dispose of any resources that can be recreated.
}

/*
 #pragma mark - Navigation
 
 // In a storyboard-based application, you will often want to do a little preparation before navigation
 - (void)prepareForSegue:(UIStoryboardSegue *)segue sender:(id)sender {
 // Get the new view controller using [segue destinationViewController].
 // Pass the selected object to the new view controller.
 }
 */

@end
